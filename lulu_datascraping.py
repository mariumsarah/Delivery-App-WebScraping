# -*- coding: utf-8 -*-
"""lulu-datascraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aW48ANAtL7CoVYNeLu0MOBZR91cJ-b2X
"""



import requests
from slimit import ast
from slimit.parser import Parser
from slimit.visitors import nodevisitor
from bs4 import BeautifulSoup
import re

pip install slimit

listed = [['HY00216087','Dairy, Eggs & Cheese'],['HY00216103','Fresh Dairy'],['HY00216088','Bakery'],['HY00216095','Cheese'],['HY00216090','Fruits & Vegetables'],['HY00216142','Fresh Juice & Salads'],['HY00216097','Cakes'],['HY00216102','Vegetables'],['HY00216151','Delicatessen'],['HY00216101','Fruits'],['HY00216098','Bread & Wraps'],['HY00216146','Fresh Meat & Fish'],['HY00216145','Fresh Juice'],['HY00216096','Eggs'],['HY00216152','Cooked Meats'],['HY00214894','Food Cupboard'],['HYGRCR00001','Grocery'],['HY00216153','Olives & Pickles'],['HY00216094','Butter & Margarine'],['HY00215240','Speciality Food'],['HY00216099','Croissants'],['HY00216159','Salads & Pizzas'],['HY00700600','Sweets'],['HY00216089','Fresh Chicken & Poultry'],['HY00216100','Fresh Chicken'],['HY00600300','Salad Vegetables'],['HY00114010','Gluten Free'],['HY00216149','Fresh Fish'],['HY00216147','Fresh Beef & Veal'],['HY00217443','Sandwiches & Burger'],['HY00114012','Vegan'],['HY00216148','Fresh Lamb & Mutton'],['HY00216155','Ready Meals'],['HY00216156','Bakes & Grills'],['HY00114009','Organic'],['HY01000600','Fruit Cuts'],['HY00214970','Biscuits & Confectionery'],['HY00214972','Biscuits'],['HY00216154','Pasta & Tortillas'],['HYUAE55','Online exclusive '],['HY00114011','Sugar Free'],['HY00216092','Longlife Milk'],['HY94000100','Hot Beverages'],['HY00214912','Breakfast & Spreads'],['HY00215244','Cheese Spreads']]
for n in listed:
    new_list = []
    sum = 0
    for x in range(0,50):
        if x == 0:
          page = requests.get("https://www.luluhypermarket.com/en-ae/fresh-food-grocery/c/"+n[0]+"?#")
        else:
          page = requests.get("https://www.luluhypermarket.com/en-ae/fresh-food-grocery/c/"+n[0]+"?page="+str(x))
        soup = BeautifulSoup(page.content, 'html.parser')
        sum += (len(soup.findAll("span", {"class": "product-discount-badge"})))
        script = soup.find('script')
        pattern = re.compile("gtm.dataLayerPlpImpression =  {\"ecommerce\":\{.*?\} ;")
        final_text = pattern.findall(script.text)
        if (len(soup.findAll("div", {"class": "totalResults"}))) == 1:
          break
        finalest1 = re.sub(r'\",\"id\".*?\n\"', '\n', final_text[0].replace('},{', '\n'))
        finalest =  re.sub(r'\",\"id\".*?} ;', '', finalest1)
        final_text = re.sub(r"gtm.dataLayerPlpImpression =  {\"ecommerce\":{\"impressions\":\[{\"","", finalest)
        for z in final_text.split('\n'):
          new_list.append("\"category:\""+n[1]+",\"type:\""+y+"\",\""+z+"\"")
    print(n[1])
    print(sum)
    print(set(new_list))
      #['Apple Inc.']

